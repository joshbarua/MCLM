question_translation_template = """You will be given an English question in the following format.

[Question]
<question>
{..question...}
</question>

Your job is to return a translated version of the question.
* Translate to <language>.
* The translation must be fluent, easy to read by native speakers.
* Do not solve the prompt translate it.
* You must preserve all details including math notations (latex) and code. 
* The math notations and code must not be translated, keep it as is.
* Return you translation in the following format.

[Translation]
<translation>
{..translated question...}
</translation>

--------------------------------------------------
The following is the math problem for you task:

[Question]
<question>
<source_question>
</question>"""


solution_translation_template = """You will be given an English solution in the following format.

[Solution]
<solution>
{..solution in English...}
</solution>

Your job is to rewrite the English solution to <language>. 
* The solution must preserve the original structure and details.
* You must preserve all details including math notations (latex) and code. 
* The math notations and code must not be translated, keep it as is.
* The solution must be natural, easy and polite for a native speaker to read.

[Translation]
<translation>
{..translated solution...}
</translation>

--------------------------------------------------
The following is the math problem and solution for your task:

[Solution]
<solution>
<source_solution>
</solution>"""

judge_template = r"""You will be given a math problem, the correct answer, and a solution generated by a language model. Your task is to determine whether the solution generated by the model is correct.

[Question]
<question>
{..math question...}
</question>

[Correct Answer]
<answer>
{..correct answer...}
</answer>

[Model Solution]
<solution>
{..model-generated solution...}
</solution>

Instructions:
* Compare the model’s solution with the correct answer.
* If the model’s solution is correct, output `[[TRUE]]`.
* If the model’s solution is incorrect, output `[[FALSE]]`.
* You do not have to judge the solution process; there are numerous possible 'Gold' solutions, and the model solution does not have to be identical with the one provided. As long as the model reaches the correct answer, it is correct.
* Do not provide any explanations—only return your judgment ONLY.

--------------------------------------------------
The following is the math problem and solution for your task:

[Question]
<question>
<math_question>
</question>

[Correct Answer]
<answer>
<correct_answer>
</answer>

[Model Solution]
<solution>
<model_solution>
</solution>"""

system_prompt = """You are a highly advanced language model. You must adhere strictly to the following guidelines when generating responses:

1. **Structured Reasoning:**
   - Present your internal chain-of-thought (trial-and-error reasoning) wrapped in `<think>` and `</think>` tags.
   - Provide a summary of your best reasoning path within `<solution>` and `</solution>` tags.
   - Accordingly, your output should be look like: <think>\n{trial-and-errors}\n<\think>\n<solution>\n{summary}\n<\solution>

2. **Output Format:**
   - Your complete response must be wrapped in the `\\boxed{ ... }` format.
   
3. **Language Consistency:**
   - Ensure that your final output is in the same language as the input.

Follow these instructions precisely for every response."""

language_dict = {
   'af': 'Afrikaans',
   'sq': 'Albanian',
   'ar': 'Arabic',
   'bn': 'Bengali',
   'bg': 'Bulgarian',
   'ca': 'Catalan',
   'zh-cn': 'Chinese_(Simplified)',
   'zh-tw': 'Chinese_(Traditional)',
   'hr': 'Croatian',
   'cs': 'Czech',
   'da': 'Danish',
   'nl': 'Dutch',
   'en': 'English',
   'et': 'Estonian',
   'fi': 'Finnish',
   'fr': 'French',
   'de': 'German',
   'el': 'Greek',
   'gu': 'Gujarati',
   'he': 'Hebrew',
   'hi': 'Hindi',
   'hu': 'Hungarian',
   'id': 'Indonesian',
   'it': 'Italian',
   'ja': 'Japanese',
   'kn': 'Kannada',
   'ko': 'Korean',
   'lv': 'Latvian',
   'lt': 'Lithuanian',
   'mk': 'Macedonian',
   'ml': 'Malayalam',
   'mr': 'Marathi',
   'ne': 'Nepali',
   'no': 'Norwegian',
   'fa': 'Persian',
   'pl': 'Polish',
   'pt': 'Portuguese',
   'pa': 'Punjabi',
   'ro': 'Romanian',
   'ru': 'Russian',
   'sk': 'Slovak',
   'sl': 'Slovenian',
   'so': 'Somali',
   'es': 'Spanish',
   'sw': 'Swahili',
   'sv': 'Swedish',
   'tl': 'Tagalog',
   'ta': 'Tamil',
   'te': 'Telugu',
   'th': 'Thai',
   'tr': 'Turkish',
   'uk': 'Ukrainian',
   'ur': 'Urdu',
   'vi': 'Vietnamese',
   'cy': 'Welsh'
}

dataset_name_dict = {
   "math100": "MT-MATH100",
   "aime2024": "MT-AIME2024",
   "IMO": "M-IMO"
}

lang_dict = {
   14: ["Afrikaans", "Arabic", "Chinese_(Simplified)", "English", "French", "German", "Hebrew", "Indonesian", "Italian", "Japanese", "Korean", "Spanish", "Turkish", "Vietnamese"],
   41: ['Albanian', 'Bengali', 'Bulgarian', 'Catalan', 'Chinese_(Traditional)', 'Croatian', 'Czech', 'Danish', 'Dutch', 'Estonian', 'Finnish', 'Greek', 'Gujarati', 'Hindi', 'Hungarian', 'Kannada', 'Latvian', 'Lithuanian', 'Macedonian', 'Malayalam', 'Marathi', 'Nepali', 'Norwegian', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Romanian', 'Russian', 'Slovak', 'Slovenian', 'Somali', 'Swahili', 'Swedish', 'Tagalog', 'Tamil', 'Telugu', 'Thai', 'Ukrainian', 'Urdu', 'Welsh'],
   55: ['Afrikaans', 'Albanian', 'Arabic', 'Bengali', 'Bulgarian', 'Catalan', 'Chinese_(Simplified)', 'Chinese_(Traditional)', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Finnish', 'French', 'German', 'Greek', 'Gujarati', 'Hebrew', 'Hindi', 'Hungarian', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Latvian', 'Lithuanian', 'Macedonian', 'Malayalam', 'Marathi', 'Nepali', 'Norwegian', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Romanian', 'Russian', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Swahili', 'Swedish', 'Tagalog', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Vietnamese', 'Welsh'],
   "IMO": ['Afrikaans', 'Albanian', 'Arabic', 'Bulgarian', 'Chinese_(Simplified)', 'Chinese_(Traditional)', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Finnish', 'French', 'German', 'Hebrew', 'Hungarian', 'Italian', 'Japanese', 'Korean', 'Latvian', 'Lithuanian', 'Macedonian', 'Norwegian', 'Polish', 'Portuguese', 'Romanian', 'Russian', 'Slovak', 'Slovenian', 'Spanish', 'Swedish', 'Thai', 'Turkish', 'Ukrainian', 'Vietnamese', 'Indonesian', 'Greek'],
   "MMO": ['Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Japanese', 'Korean', 'Polish', 'Russian', 'Slovakia'],
}

system_prompt_dict = {
   "jwhj/Qwen2.5-Math-1.5B-OREO": "Please reason step by step, and put your final answer within \\boxed{}.",
   "PRIME-RL/Eurus-2-7B-PRIME": "\n\nPresent the answer in LaTex format: \\boxed{Your answer}",
   "Qwen/Qwen2.5-Math-1.5B-Instruct": "Please reason step by step, and put your final answer within \\boxed{}.",
   "Qwen/Qwen2.5-Math-7B-Instruct": "Please reason step by step, and put your final answer within \\boxed{}."
}